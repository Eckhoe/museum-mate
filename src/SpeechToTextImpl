// Handles working with browser speech recognition API
class SpeechToText {
    constructor(onFinal, onEnd, onSaid) {
        var _this = this;

        var language = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 'en-US';

        if (!('webkitSpeechRecognition' in window)) {
            throw new Error("This browser doesn't support speech recognition. Try Google Chrome.");
        }

        var SpeechRecognition = window.webkitSpeechRecognition;
        this.recognition = new SpeechRecognition(); // set results to be returned if a callback for it has been passed in

        this.recognition.interimResults = !!onSaid;
        this.recognition.lang = language;
        var finalTranscript = ''; // process both interim and finalised results

        this.recognition.onresult = function (event) {
            var interimTranscript = ''; // concatenate all the transcribed pieces together (SpeechRecognitionResult)

            for (var i = event.resultIndex; i < event.results.length; i += 1) {
                var transcriptionPiece = event.results[i][0].transcript; // check for a finalised transciption in the cloud

                if (event.results[i].isFinal) {
                    finalTranscript += transcriptionPiece;
                    onFinal(finalTranscript);
                    finalTranscript = '';
                } else if (_this.recognition.interimResults) {
                    interimTranscript += transcriptionPiece;
                    onSaid(interimTranscript);
                }
            }
        };

        this.recognition.onend = function () {
            onEnd();
        };

        this.Listen = function () {
            this.recognition.start();
        };

        this.Stop = function () {
            this.recognition.stop();
        };
    }
}

// Contains callbacks for when results are returned
class STTSpeechAPI {
    constructor(language = 'en-US') {
        this.stt = new SpeechToText(this.onFinal, this.onStop, this.onInterimResult, language)
    }

    Listen() {
        this.stt.Listen()
    }

    Stop() {
        this.stt.Stop()
    }

    End() {
        this.stt.recognition.End()
        this.stt.Stop()
    }

    onFinal(text) {
        const m = {
            text,
            final: true,
        }
        window.sap.cai.webclient.onSTTResult(m)
    }

    onInterimResult(text) {
        const m = {
            text,
            final: false,
        }
        window.sap.cai.webclient.onSTTResult(m)
    }

    onStop() {
        const m = {
            text: '',
            final: true,
        }
        window.sap.cai.webclient.onSTTResult(m)
    }
}

// Contains methods SAP Conversational AI needs for handling
// chatbot UI events
let stt = null
const sttSpeech = {
    sttConfig: async () => {
         return {
            useMediaRecorder: false,
        }
    },

    sttListen: async (params) => {
        const [metadata] = params
        const { language, _ } = metadata

        stt = new STTSpeechAPI(language)
        stt.Listen()
    },

    sttStop: () => {
        stt.Stop()
    },

    sttEnd: () => {
        stt.End()
    },
}

window.clientIm = sttSpeech